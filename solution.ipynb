{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70decff3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Exercise 1: Introduction to Deep Learning\n",
    "<div>\n",
    "    <table>\n",
    "        <tr style=\"background-color:white\">\n",
    "            <td><img src=\"attachments/perceptron.png\" width=\"100%\"/></td>\n",
    "            <td><img src=\"attachments/mlp.png\" width=\"100%\"/></td>\n",
    "            <td><img src=\"attachments/neural_network.png\" width=\"100%\"/></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "In the following exercise we will explore the basic building blocks of deep learning: the perceptron and how to stack multiple perceptrons together into layers to build a neural network. We will also introduce convolutional neural networks (CNNs) for image classification.\n",
    "In particular, we will:\n",
    "- Implement a perceptron and a 2-layer perceptron to compute the XOR function using NumPy.\n",
    "- Introduce PyTorch, a popular framework for deep learning.\n",
    "- Implement and train a simple neural network (a multi-layer perceptron, or simply MLP) to classify points in a 2D plane using PyTorch.\n",
    "- Implement and train a simple convolutional neural network to classify hand-written digits from the MNIST dataset using PyTorch.\n",
    "- Discuss important topics in ML/DL, such as data splitting, under/overfitting and model generalization.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    Set your python kernel to <code>01_intro_dl</code>\n",
    "    <tr style=\"background-color:white\">\n",
    "        <td><img src=\"attachments/kernel-change.png\" width=\"100%\"/></td>\n",
    "    </tr>\n",
    "</div>\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "The original notebook was created by Nils Eckstein, Julia Buhmann, and Jan Funke. Albert Dominguez Mantes ported the notebook to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 5) # this line sets the default size of plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb69c96",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 1: Perceptrons\n",
    "\n",
    "<div>\n",
    "    <img src=\"attachments/perceptron.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "As we saw in the lecture [\"Introduction to Deep Learning\"](intro_dl_lecture.pdf), a perceptron is a simple unit that combines its inputs $x_i$ in a linear fashion (using weights $w_i$ and a bias $b$), followed by a non-linear function $f$.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task 1</b>: Implement a Perceptron Function\n",
    "</div>\n",
    "\n",
    "Using only `numpy`, write a function `perceptron(x, w, b, f)` that returns `y` as computed by a perceptron, for arbitrary inputs `x` of dimension `n`. The arguments of your function should be:\n",
    "\n",
    "* `x`: the input of the perceptron, a `numpy` array of shape `(n,)`\n",
    "* `w`: the weights of the perceptron, a `numpy` array of shape `(n,)`\n",
    "* `b`: a single scalar value for the bias\n",
    "* `f`: a nonlinear function $f: \\mathbb{R}\\mapsto\\{0, 1\\}$\n",
    "\n",
    "Test your perceptron function on 2D inputs (i.e., `n=2`) and plot the result. Change the weights, bias, and the function $f$ and see how the output of the perceptron changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd508953",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def non_linearity(a):\n",
    "    \"\"\"This non-linearity is called the step function.\n",
    "       NOTE: this function is not differentiable, and thus\n",
    "       is not cannot be used in gradient descent.\n",
    "    \"\"\"\n",
    "    return a > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15415fe",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def perceptron(x, w, b, f):\n",
    "    return f(np.sum(x * w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e29a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def plot_perceptron(w, b, f):\n",
    "    \"\"\"This function will evaluate the perceptron on a grid of arbitrary points\n",
    "       (equispaced across 0-1) and plot the result in each point, which will reveal\n",
    "       the decision boundary of the perceptron.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = 100 # number of samples in each dimension\n",
    "    domain_x1 = (0.0, 1.0) # domain of the plot (x-axis)\n",
    "    domain_x2 = (0.0, 1.0) # domain of the plot (y-axis)\n",
    "\n",
    "    domain = np.meshgrid(\n",
    "        np.linspace(*domain_x1, num_samples), np.linspace(*domain_x2, num_samples)\n",
    "    ) # create a grid of equispaced points in the domain\n",
    "\n",
    "    xs = np.array([domain[0].flatten(), domain[1].flatten()]).T # format the points as a list of 2D points to evaluate the perceptron on\n",
    "\n",
    "    values = np.array([perceptron(x, w, b, f) for x in xs]) # evaluate the perceptron on each point in the grid\n",
    "\n",
    "    plt.contourf(domain[0], domain[1], values.reshape(num_samples, num_samples)) # plot the result as filled contours\n",
    "\n",
    "\n",
    "# the following should show a linear classifier that is True (shown as green)\n",
    "# for values below a line starting at (0.1, 0) through (1.0, 0.9)\n",
    "plot_perceptron(w=[1.0, -1.0], b=-0.1, f=non_linearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738db86",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2> Checkpoint 1 </h2>\n",
    "You have implemented a perceptron using basic Python and NumPy functions, as well as checked what the perceptron decision boundary looks like.\n",
    "We will now go over different ways to implement the perceptron together and discuss their efficiency. If you arrived here earlier, feel free to play around with the parameters of the perceptron (the weights and bias) as well as the activation function <code>f</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d1c0a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h2>Task 2</h2>\n",
    "    \n",
    "Create a 2-Layer Network for XOR\n",
    "</div>\n",
    "\n",
    "XOR is a fundamental logic gate that outputs `1` whenever there is an odd number of `1` in its input and `0` otherwise. For two inputs this can be thought of as an \"exclusive or\" operation and the associated boolean function is fully characterized by the following truth table.\n",
    "\n",
    "| x1 | x2 | y = XOR(x1, x2) |\n",
    "|---|---|----------|\n",
    "| 0 | 0 |    0     |\n",
    "| 0 | 1 |    1     |\n",
    "| 1 | 0 |    1     |\n",
    "| 1 | 1 |    0     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff8803",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def generate_xor_data():\n",
    "    \"\"\"Generate XOR data for pairs of binary inputs:\n",
    "    f(0,0) = 0\n",
    "    f(0,1) = 1\n",
    "    f(1,0) = 1\n",
    "    f(1,1) = 0\n",
    "    \"\"\"\n",
    "    xs = [np.array([i, j]) for i in [0, 1] for j in [0, 1]]\n",
    "    ys = [int(np.logical_xor(x[0], x[1])) for x in xs]\n",
    "    return xs, ys\n",
    "\n",
    "def plot_xor_data():\n",
    "    \"\"\"Plot the XOR data. Class 0 points are shown in red, class 1 points in green.\n",
    "    \"\"\"\n",
    "    xs, ys = generate_xor_data()\n",
    "    for x, y in zip(xs, ys):\n",
    "        plt.scatter(*x, color=\"green\" if y else \"red\")\n",
    "    \n",
    "    plt.xticks([0, 1])\n",
    "    plt.yticks([0, 1])\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_frame_on(False)\n",
    "    plt.show()\n",
    "\n",
    "plot_xor_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a74dec6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "source": [
    "The function of an XOR gate can also be understood as a binary classification problem given a 2D binary inputs $x$ ($x \\in \\{0,1\\}^2$ and we can think about designing a classifier acting as an XOR gate. It turns out that this problem is not solvable by a single perceptron (https://en.wikipedia.org/wiki/Perceptron) because the set of points $\\{(0,0), (0,1), (1,0), (1,1)\\}$ is not linearly separable.\n",
    "\n",
    "![mlp.png](attachments/mlp.png)\n",
    "\n",
    "Design a two layer perceptron using your `perceptron` function above that implements an XOR Gate on two inputs. Think about the flow of information through this simple network and set the weight values by hand such that the network produces the XOR function.\n",
    "\n",
    "#### Hint\n",
    "\n",
    "A single layer in a multilayer perceptron can be described by the equation $y = f(x^\\intercal w + b)$, where $f$ denotes a non-linear function, $b$ denotes the bias (a constant offset vector) and $w$ denotes a vector of weights. Since we are only interested in boolean outputs ($\\{0,1\\}$), a good choice for $f$ is the threshold function. Think about which kind of logical operations you can implement with a single perceptron, then see how you can combine them to create an XOR. It might help to write down the equation for a two layer perceptron network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ff175",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def xor(x):\n",
    "    # SOLUTION\n",
    "    w11 = [0.1, 0.1] # weights of the first perceptron in the first layer\n",
    "    b11 = -0.05 # bias of the first perceptron in the first layer\n",
    "    w12 = [0.1, 0.1] # weights of the second perceptron in the first layer\n",
    "    b12 = -0.15 # bias of the second perceptron in the first layer\n",
    "    w2 = [0.1, -0.1] # weights of the perceptron in the last layer\n",
    "    b2 = -0.05 # bias of the perceptron in the last layer\n",
    "    f = lambda a: a > 0 # activation function of the perceptrons (threshold function)\n",
    "\n",
    "    # output of the two perceptrons in the first layer\n",
    "    h1 = perceptron(x, w=w11, b=b11, f=f)\n",
    "    h2 = perceptron(x, w=w12, b=b12, f=f)\n",
    "    # output of the perceptron in the last layer\n",
    "    y = perceptron(np.array([h1, h2]), w=w2, b=b2, f=f)  # h1 AND NOT h2\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e50830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xor():\n",
    "    xs, ys = generate_xor_data()\n",
    "    for x, y in zip(xs, ys):\n",
    "        assert (\n",
    "            xor(x) == y\n",
    "        ), f\"xor function returned {int(xor(x))} for input {x}, but should be {y}\"\n",
    "        print(f\"XOR of {x} is {y}, your implementation returns {int(xor(x))}\")\n",
    "    print(\"\\nCongratulations! You have implemented the XOR function correctly.\")\n",
    "\n",
    "\n",
    "test_xor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699e504a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2> Checkpoint 2 </h2>\n",
    "You have been introduced to the XOR gate and its view as a binary classification problem. You have also solved XOR using a two-layer perceptron.\n",
    "There are many ways to implement an XOR in a two-layer perceptron. We will review some of them and how we got to them (trial and error or pen and paper?).\n",
    "    \n",
    "<br/>\n",
    "If you arrive here early, think about how to generalize the XOR function to an arbitrary number of inputs. For more than two inputs, the XOR returns True if the number of 1s in the inputs is odd, and False otherwise.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d16cc9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Part 2: \"Deep\" Neural Networks\n",
    "\n",
    "<div>\n",
    "    <img src=\"attachments/neural_network.png\" width=500/>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h2>Task 3</h2>\n",
    "\n",
    "Use PyTorch to Train a Simple Network\n",
    "</div>\n",
    "\n",
    "The previous task demonstrated that chosing the weights of a neural network by hand can be quite painful even for simple functions. This will certainly get out of hand once we have more complex networks with several layers and many neurons per layer. But more importantly, the reason why we want to use neural networks to approximate a function is that (in general) we do not know exactly what the function is. We only have data points that describe the function implicitly.\n",
    "\n",
    "In this task, we will design, train, and evaluate a neural network that can classify points of two different classes on a 2D plane, i.e., the input to our network are the coordinates of points in a plane.\n",
    "\n",
    "For that, we will create a training and a testing dataset. We will use stochastic gradient descent to train a network on the training dataset and evaluate its performance on the testing dataset.\n",
    "\n",
    "#### Data\n",
    "\n",
    "We create both training and testing dataset from the following function (in practice, we would not know this function but have only the data available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spiral_data(n_points, noise=1.0):\n",
    "    n = np.sqrt(np.random.rand(n_points, 1)) * 780 * (2 * np.pi) / 360\n",
    "    d1x = -np.cos(n) * n + np.random.rand(n_points, 1) * noise\n",
    "    d1y = np.sin(n) * n + np.random.rand(n_points, 1) * noise\n",
    "    return (\n",
    "        np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y)))),\n",
    "        np.hstack((np.zeros(n_points), np.ones(n_points))),\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_points(Xs, ys, titles):\n",
    "    num_subplots = len(Xs)\n",
    "    plt.subplots(1, num_subplots, figsize=(5 * num_subplots, 5))\n",
    "    for i, (X, y, title) in enumerate(zip(Xs, ys, titles)):\n",
    "        plt.subplot(1, num_subplots, i + 1)\n",
    "        plt.title(title)\n",
    "        plt.plot(X[y == 0, 0], X[y == 0, 1], \".\", label=\"Class 1\")\n",
    "        plt.plot(X[y == 1, 0], X[y == 1, 1], \".\", label=\"Class 2\")\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "X_train, y_train = generate_spiral_data(100)\n",
    "X_test, y_test = generate_spiral_data(1000)\n",
    "\n",
    "plot_points([X_train, X_test], [y_train, y_test], [\"Training Data\", \"Testing Data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7fa76",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We will start with a simple baseline model. But first, we will explicitly write the training loop (required by vanilla PyTorch), which you have gone through in the lecture. Comments in the code will help you identify the different steps involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def batch_generator(X, y, batch_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        # Shuffle the data at each epoch\n",
    "        indices = np.random.permutation(len(X))\n",
    "    else:\n",
    "        # Process the data in the order as it is\n",
    "        indices = np.arange(len(X))\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield X[indices[i : i + batch_size]], y[indices[i : i + batch_size]]\n",
    "\n",
    "\n",
    "def run_epoch(model, optimizer, X_train, y_train, batch_size, loss_fn, device):\n",
    "    n_samples = len(X_train)\n",
    "    total_loss = 0\n",
    "\n",
    "    # Set the model to training mode, essential when using certain layers\n",
    "    model.train()\n",
    "    for X_b, y_b in batch_generator(X_train, y_train, batch_size):\n",
    "        # Convert the data to PyTorch tensors\n",
    "        X_b = torch.tensor(X_b, dtype=torch.float32, device=device)\n",
    "        y_b = torch.tensor(y_b, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Reset the optimizer state\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: pass the data through the model and retrieve the prediction\n",
    "        y_pred = model(X_b).squeeze()\n",
    "        # Note: the .squeeze() method above removes dimensions of size 1, which is useful in this case as we are predicting a single value.\n",
    "        # Before squeezing, the shape would be (B, 1). After squeezing, it is (B,), which is the shape of our target values y_b.\n",
    "        # The inverse of .squeeze() is .unsqueeze(), which adds dimensions of size 1. This is useful when e.g. you want to add a batch dimension to a single sample, or a channel dimension in a single-channel image.\n",
    "\n",
    "        # Compute the loss function with the prediction and the ground truth\n",
    "        loss = loss_fn(y_pred, y_b)\n",
    "        # Note: even if a single number is returned, it is still a tensor with an associated computational graph (--> more memory used).\n",
    "        # Be extremely careful when using the loss tensor in other calculations (e.g. for monitoring issues), as it can lead to memory leaks and other errors.\n",
    "        # For those, you should always use the .item() method to convert to a native Python number (see the last comment of the function).\n",
    "\n",
    "        # Backward pass: compute the gradient of the loss w.r.t. the parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss (for monitoring purposes)\n",
    "        total_loss += loss.item() # the .item() converts the single-number Tensor to a Python floating point number, avoiding retaining the computational graph in the loss tensor\n",
    "    return total_loss / n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a93f6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Before continuing, you should know that PyTorch is object-oriented (OOP) and follows specific class structures. If you are not too familiar with Python or OOP, it may be a bit tricky to understand the structure at first, and what executes when. Don't despair! Getting the grasp on it is easier than it seems. Here we will focus on getting the architecture of the model right, so most of the boilerplate work will be already lifted.\n",
    "\n",
    "So, let's now write the simple baseline model, consisting of one hidden layer with 12 neurons (or perceptrons). You will see that this baseline model performs pretty poorly. Read the following code snippets and try to understand the involved functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU not available. Will use CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"This method (:= `constructor`) is automatically called when the class instance is created, i.e. `model = BaselineModel()`\n",
    "        Note that this initializes the model architecture, but does not yet apply it to any data. This is done in the `forward` method.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # The input to the next block is a tensor of size (B, 2), where 2 is the number of features.\n",
    "        # The block then sequentially applies a linear transformation, a non-linear activation function, another linear transformation, and another non-linear activation function.\n",
    "        # The output of the following block is a tensor of size (B, 1), where B is the batch size, which will be the predicted class of the input data.\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=2, out_features=12, bias=True), # this layer receives a tensor of size (B, 2) and returns a tensor of size (B, 12)\n",
    "            nn.Tanh(), # Tanh is a non-linear activation function that squashes the output to the range [-1, 1]\n",
    "            nn.Linear(in_features=12, out_features=1), # this layer receives a tensor of size (B, 12) and returns a tensor of size (B, 1)\n",
    "            nn.Sigmoid(), # Sigmoid is a non-linear activation function that squashes the output to the range [0, 1], widely used for binary classification\n",
    "        )\n",
    "        # Note: the output of the block is a number between 0 and 1. In simplifying terms, you can think of it as \"the probability of the input data belonging to class 1\".\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"This method can be called to perform a forward pass of the model.\n",
    "           It is automatically called when the class instance is called as a function, i.e. `model(x)`, which is highly recommended (so, in general, don't use model.forward(x) but model(x)).\n",
    "           In this example we have one module, but you can have multiple modules and combine them here.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input data, which should have the shape (B, 2) in this case, where B is the batch size\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: results of applying the model to the input data, Shape will be (B, 1)\n",
    "        \"\"\"\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "# Initialize the model, optimizer and set the loss function\n",
    "bad_model = BaselineModel()\n",
    "# The .to() method will move the model to the appropiate device (e.g. the GPU if available)\n",
    "bad_model.to(device)\n",
    "optimizer = torch.optim.SGD(\n",
    "    bad_model.parameters(), lr=0.01\n",
    ")  # SGD - Stochastic Gradient Descent\n",
    "loss_fn = nn.MSELoss(reduction=\"sum\")  # MSELoss - Mean Squared Error Loss\n",
    "\n",
    "batch_size = 10\n",
    "num_epochs = 1500\n",
    "\n",
    "\n",
    "for epoch in (pbar := tqdm(range(num_epochs), total=num_epochs, desc=\"Training\")):\n",
    "    # Run an epoch over the training set\n",
    "    curr_loss = run_epoch(\n",
    "        bad_model, optimizer, X_train, y_train, batch_size, loss_fn, device\n",
    "    )\n",
    "\n",
    "    # Update the progress bar to display the training loss\n",
    "    pbar.set_postfix({\"training loss\": curr_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95184275",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now that we've trained the model, let's evaluate its performance on the testing dataset. The following code snippet will retrieve the predictions from the model, and will then plot them along with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y, batch_size, device):\n",
    "    predictions = np.empty((0,))\n",
    "    model.eval() # set the model to evaluation mode\n",
    "    with torch.inference_mode(): # this \"context manager\" is used to disable gradient computation (among others), which is not needed during inference and offers improved performance\n",
    "        for X_b, y_b in batch_generator(X, y, batch_size, shuffle=False):\n",
    "            X_b = torch.tensor(X_b, dtype=torch.float32, device=device)\n",
    "            y_b = torch.tensor(y_b, dtype=torch.float32, device=device)\n",
    "            y_pred = model(X_b).squeeze().detach().cpu().numpy()\n",
    "            # Note: the last chain of methods (in order) do: remove a unit dimension (.squeeze()),\n",
    "            # detach the tensor from the computational graph (.detach()),\n",
    "            # move it to the CPU (.cpu()),\n",
    "            # and convert it to a NumPy array (.numpy())\n",
    "            predictions = np.concatenate((predictions, y_pred), axis=0)\n",
    "    return np.round(predictions)\n",
    "\n",
    "\n",
    "def accuracy(y_pred, y_gt):\n",
    "    return np.sum(y_pred == y_gt) / len(y_gt)\n",
    "\n",
    "\n",
    "bad_predictions = predict(bad_model, X_test, y_test, batch_size, device)\n",
    "bad_accuracy = accuracy(bad_predictions, y_test)\n",
    "\n",
    "plot_points(\n",
    "    [X_test, X_test],\n",
    "    [y_test, bad_predictions],\n",
    "    [\"Testing data\", f\"Bad Model Classification ({bad_accuracy * 100:.2f}% correct)\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9a997",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task 3.1</b>: Improve the Baseline Model\n",
    "</div>\n",
    "\n",
    "Now, try to find a more advanced architecture that is able to solve the classification problem. You can vary width (number of neurons per layer) and depth (number of layers) of the network. You can also play around with [different activation functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity), [loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions), and [optimizers](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "Hint: some commonly used losses are `nn.BCELoss()` (binary crossentropy loss), `nn.MSELoss()` or `nn.L1Loss()` (one of them is particularly used for binary problems... :)). Some commonly used optimizers, apart from `torch.optim.SGD()`, are `torch.optim.AdamW()`, or `torch.optim.Adagrad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c5dea",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class GoodModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            # SOLUTION\n",
    "            nn.Linear(in_features=2, out_features=64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=64, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "good_model = GoodModel()\n",
    "good_model.to(device)\n",
    "\n",
    "# SOLUTION\n",
    "optimizer = torch.optim.AdamW(good_model.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss(reduction=\"sum\")  # Binary Cross Entropy Loss\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "num_epochs = 1500\n",
    "\n",
    "\n",
    "good_model.train()\n",
    "for epoch in (pbar := tqdm(range(num_epochs), total=num_epochs, desc=\"Training\")):\n",
    "    # Run an epoch over the training set\n",
    "    curr_loss = run_epoch(\n",
    "        good_model, optimizer, X_train, y_train, batch_size, loss_fn, device\n",
    "    )\n",
    "\n",
    "    # Update the progress bar to display the training loss\n",
    "    pbar.set_postfix({\"training loss\": curr_loss})\n",
    "\n",
    "good_predictions = predict(good_model, X_test, y_test, batch_size, device)\n",
    "good_accuracy = accuracy(good_predictions, y_test)\n",
    "\n",
    "plot_points(\n",
    "    [X_test, X_test],\n",
    "    [y_test, good_predictions],\n",
    "    [\"Testing data\", f\"Good Model Classification ({good_accuracy * 100:.2f}% correct)\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ead16",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task 3.2</b>: Visualize Your Model\n",
    "</div>\n",
    "\n",
    "The next cell visualizes the output of your model for all 2D inputs with coordinates between 0 and 1, similar to how we plotted the output of the perceptron in **Task 1**. Change the code below to show the domain -15 to 15 for both input dimensions and compare the outputs of the `bad_model` model with yours. See also how the model performs outside the intervals it was trained on by increasing the domain even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375fa046",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_classifiers(classifier_1, classifier_2):\n",
    "\n",
    "    plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    num_samples = 200\n",
    "\n",
    "    # SOLUTION\n",
    "    domain_x1 = (-100.0, 100.0)\n",
    "    domain_x2 = (-100.0, 100.0)\n",
    "\n",
    "    domain = np.meshgrid(\n",
    "        np.linspace(*domain_x1, num_samples), np.linspace(*domain_x2, num_samples)\n",
    "    )\n",
    "    xs = np.array([domain[0].flatten(), domain[1].flatten()]).T\n",
    "\n",
    "    values_1 = predict(classifier_1, xs, np.zeros(xs.shape[0]), batch_size, device)\n",
    "    values_2 = predict(classifier_2, xs, np.zeros(xs.shape[0]), batch_size, device)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Bad Model\")\n",
    "    plt.contourf(domain[0], domain[1], values_1.reshape(num_samples, num_samples))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Good Model\")\n",
    "    plt.contourf(domain[0], domain[1], values_2.reshape(num_samples, num_samples))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_classifiers(bad_model, good_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237cb6f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Question:</b>\n",
    "    Looking at the classifier on an extended domain, what observations can you make?\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2> Checkpoint 3</h2>\n",
    "You have now been introduced to PyTorch and trained a simple neural network on a binary classification problem. You have also seen how to visualize the decision function of the model, and what happens if the model is applied to a domain it had not seen during training.\n",
    "Let us know in the exercise channel when you got here and what accuracy your model achieved! We will compare different solutions and discuss why some of them are better than others. We will also discuss the generalization behaviour of the classifier outside of the domain it was trained on.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e099a5",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h2>Task 4</h2>\n",
    "\n",
    "Classify Hand-Written Digits\n",
    "</div>\n",
    "\n",
    "In this task, we will classify data points of higher dimensions: Each data point is now an image of size 28 by 28 pixels depicting a hand-written digit from the famous MNIST dataset.\n",
    "\n",
    "Instead of feeding the image as one long vector into a fully connected network (as in the previous task), we will take advantage of the spatial information in images and use a convolutional neural network. As a reminder, a convolutional neural network differs from a fully connected one in that not each pair of nodes is connected, and weights are shared between nodes in one layer:\n",
    "\n",
    "<div>\n",
    "<img src=\"attachments/convolutional_network.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "However, the output of our network will be a 10-dimensional vector, indicating the probabilities for the input to be one of ten classes (corresponding to the digits 0 to 9). For that, we will use fully connected layers at the end of our network, once the dimensionality of a feature map is small enough to capture high-level information.\n",
    "\n",
    "In principle, we could just use convolutional layers to reduce the size of each feature map by 2 until one feature map is small enough to allow using a fully connected layer. However, in many network architectures, you will find a convolutional layer followed by a so-called downsampling layer, which effectively reduces the size of the feature map by the downsampling factor. Whether a downsampling layer will be beneficial or not depends mostly on the specific problem to be dealt with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3bd1c1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Data\n",
    "The following snippet will download the MNIST dataset using the `torchvision` library. The `transforms=transforms.ToTensor()` parameter will ensure that the data format is appropriate for using it directly (adding a channel dimension, rescaling values between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "all_train_ds = MNIST(\n",
    "    root=\"mnist_data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "test_ds = MNIST(\n",
    "    root=\"mnist_data\", train=False, download=True, transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84110a33",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "The dataset is already split into training and test data, but we will further split the training data into training and validation, and show a few samples in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_all_train_samples = len(all_train_ds)\n",
    "train_ds, val_ds = torch.utils.data.random_split(\n",
    "    all_train_ds, [int(0.8 * num_all_train_samples), int(0.2 * num_all_train_samples)]\n",
    ")\n",
    "\n",
    "print(f\"Training data has {len(train_ds)} samples\")\n",
    "print(f\"Validation data has {len(val_ds)} samples\")\n",
    "print(f\"Testing data has {len(test_ds)} samples\")\n",
    "\n",
    "\n",
    "def show_samples(dataset, title, predictions=None, num_samples=10):\n",
    "    plt.close()\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(3 * num_samples, 3))\n",
    "    fig.suptitle(title, size=40, y=1.2)\n",
    "    if predictions is not None:\n",
    "        assert len(predictions) == len(\n",
    "            dataset\n",
    "        ), \"Number of given predictions must match number of samples\"\n",
    "    for i in range(num_samples):\n",
    "        img, label = dataset[i]\n",
    "        if predictions is not None:\n",
    "            label = int(predictions[i])\n",
    "        img = img.squeeze().numpy()\n",
    "        axs[i].imshow(img, cmap=\"gray\")\n",
    "        (\n",
    "            axs[i].set_title(f\"Label: {label}\")\n",
    "            if predictions is None\n",
    "            else axs[i].set_title(f\"Prediction: {label}\")\n",
    "        )\n",
    "        axs[i].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_samples(train_ds, \"Training Data\")\n",
    "show_samples(val_ds, \"Validation Data\")\n",
    "show_samples(test_ds, \"Testing Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0eb540",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "Let us make sure that the data is in the right format for using with `torch` modules. Convolutional layers expect an input shape of (B, C, H, W) (batch, channel, height and width). The batch dimension represents different samples in a batch. Therefore, each sample (image) in our dataset should be (1,28,28), as the data is single-channel. We will also check the labels to make sure they are integers between 0 and 9.\n",
    "\n",
    "While manually checking a couple of images is fine (and recommended), it is also good to automatize this process and check the data format in general (as long as the size allows so!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training image shape:\", train_ds[0][0].shape)\n",
    "print(\"Training image label:\", train_ds[0][1])\n",
    "\n",
    "print(\"Validation image shape:\", val_ds[0][0].shape)\n",
    "print(\"Validation image label:\", val_ds[0][1])\n",
    "\n",
    "print(\"Testing image shape:\", test_ds[0][0].shape)\n",
    "print(\"Testing image label:\", test_ds[0][1])\n",
    "\n",
    "assert all(\n",
    "    img.shape == (1, 28, 28) and isinstance(label, int) and 0 <= label <= 9\n",
    "    for img, label in train_ds\n",
    "), \"Unexpected shape, type or label for training data\"\n",
    "\n",
    "assert all(\n",
    "    img.shape == (1, 28, 28) and isinstance(label, int) and 0 <= label <= 9\n",
    "    for img, label in val_ds\n",
    "), \"Unexpected shape, type or label for validation data\"\n",
    "\n",
    "assert all(\n",
    "    img.shape == (1, 28, 28) and isinstance(label, int) and 0 <= label <= 9\n",
    "    for img, label in test_ds\n",
    "), \"Unexpected shape, type or label for test data\"\n",
    "print(\"\\nData format is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bcc2d2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task 4.1</b>: Implement a Convolutional Neural Network\n",
    "</div>\n",
    "\n",
    "Create a CNN using `torch` module with the following specifications:\n",
    "* one convolution, size 3x3, 32 output feature maps, padding=1, followed by a ReLU activation function\n",
    "* one downsampling layer, size 2x2, via max-pooling\n",
    "* one convolution, size 3x3, 32 output feature maps, padding=1, followed by a ReLU activation function\n",
    "* one downsampling layer, size 2x2, via max-pooling\n",
    "* one fully connected (linear) layer with 64 units (the previous feature maps need to be flattened for that), followed by a ReLU activation function\n",
    "* one fully connected (linear) layer with 10 units, **without any activation function**. The output of this layer will be the logits.\n",
    "\n",
    "The fact that we do not add any activation function in the output is because certain loss functions in PyTorch (e.g. [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) expect the logits given by the network and already apply the activation function in a more efficient manner when computing the loss, offering speedup and more numerical stability compared to explicitly adding it. Therefore, one should not to add an activation function in the output layer when using these loss functions during training (always double check what is the expected input for the loss function you want to use!).\n",
    "\n",
    "Each layer above has a corresponding `torch` implementation (e.g., a convolutional layer is implemented by [`nn.Conv2D`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), and the linear layer by [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html), which you have used before in Task 3). Please find the other necessary modules by browsing the [torch.nn documentation](https://pytorch.org/docs/stable/nn.html)! Flattening can be achieved by using the [`nn.Flatten` module](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) with its default parameters.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Question:</b>\n",
    "    PyTorch requires explicitly giving the number of input features/channels to each Linear/Conv2D layer. Therefore, you need to know the number of input features/channels for those layers.\n",
    "    What is the number of input features/channels for each layer in the CNN described above? Take particular care with the number of input features in the first fully connected layer (after flattening). You can assume the convolutional layers will preserve the input spatial size (thanks to the `padding=1`). Downsampling operations do not change the number of channels/feature maps, they simply reduce the spatial size by the pooling factor. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d267d",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the layers of the model\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_features=32 * 7 * 7, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv(x)\n",
    "        y = self.dense(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "cnn_model = CNNModel()\n",
    "\n",
    "try:\n",
    "    cnn_model(torch.zeros(1, 1, 28, 28))\n",
    "except RuntimeError as e:\n",
    "    if str(e).startswith(\"mat1 and mat2 shapes cannot be multiplied\"):\n",
    "        print(\n",
    "            f\"The model does not work with the input shape. Please double check the number of features/channels for the fully connected layers. The error is:\\n{e}\"\n",
    "        )\n",
    "    else:\n",
    "        raise e\n",
    "print(\n",
    "    \"Trainable params:\",\n",
    "    sum(p.numel() for p in cnn_model.parameters() if p.requires_grad),\n",
    ")\n",
    "del cnn_model  # clean up the temporary model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a05345",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "The last line in the previous cell prints the number of trainable parameters of your model. This number should be 110634.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Task 4.2</b>: Train the Network\n",
    "</div>\n",
    "\n",
    "As we did for Task 3, we will define some auxiliary functions for the training procedure which include, as before, the training loop (which we rewrite to add the computation of a metric to monitor during training), but also a validation procedure which will be used to evaluate the model on the validation dataset on every epoch.\n",
    "\n",
    "Moreover, these procedures will use the very commonly used `DataLoader` class to deal with the data in batches. This PyTorch module allows an easy interface to iterate over the data in batches and comes with many benefits, such as the potential to load the data quicker with parallel processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, optimizer, train_dataloader, loss_fn, device):\n",
    "    n_samples = len(train_dataloader.dataset)\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for X_b, y_b in train_dataloader:\n",
    "        # Convert the data to PyTorch tensors\n",
    "        X_b = X_b.to(device)\n",
    "        y_b = y_b.long().to(\n",
    "            device\n",
    "        )  # Ensure the labels are of type long (int) as required by the loss function nn.CrossEntropyLoss\n",
    "\n",
    "        # Reset the optimizer state\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: pass the data through the model and retrieve the prediction\n",
    "        y_pred = model(X_b).squeeze()\n",
    "\n",
    "        # Compute the loss function with the prediction and the ground truth\n",
    "        loss = loss_fn(y_pred, y_b)\n",
    "\n",
    "        # Backward pass: compute the gradient of the loss w.r.t. the parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss (for monitoring purposes)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute the number of correct predictions\n",
    "        total_correct += (y_pred.argmax(dim=1) == y_b).sum().item()\n",
    "    train_loss = total_loss / n_samples\n",
    "    train_accuracy = total_correct / n_samples\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def validate(model, val_dataloader, loss_fn, device):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    n_samples = len(val_dataloader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_b, y_b in val_dataloader:\n",
    "            X_b = X_b.to(device)\n",
    "            y_b = y_b.long().to(device)\n",
    "            y_pred = model(X_b)\n",
    "            total_loss += loss_fn(y_pred, y_b).item()\n",
    "            total_correct += (y_pred.argmax(dim=1) == y_b).sum().item()\n",
    "    val_loss = total_loss / n_samples\n",
    "    val_accuracy = total_correct / n_samples\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a2d4e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Below we define a helper function to visualize the training and validation loss and accuracies live during training. We will use it to monitor the training process of the network, and later to discuss some central concepts of ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e239d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def live_training_plot(\n",
    "    train_loss, val_loss, train_acc, val_acc, num_epochs=10, figsize=(10, 5)\n",
    "):\n",
    "    clear_output(wait=True)\n",
    "    plt.close()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    axs[0].plot(train_loss, label=\"Training loss\")\n",
    "    axs[0].plot(val_loss, label=\"Validation loss\")\n",
    "\n",
    "    axs[1].plot(train_acc, label=\"Training accuracy\")\n",
    "    axs[1].plot(val_acc, label=\"Validation accuracy\")\n",
    "\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "    axs[0].set_title(\"Loss\")\n",
    "    axs[1].set_title(\"Accuracy\")\n",
    "\n",
    "    axs[0].set_xlim(0, num_epochs - 1)\n",
    "    axs[1].set_xlim(0, num_epochs - 1)\n",
    "\n",
    "    axs[0].legend(loc=\"upper right\")\n",
    "    axs[1].legend(loc=\"lower right\")\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51251992",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We are now ready to train the network!\n",
    "\n",
    "Instantiate and fit your `cnn_model` similar to how you did for the spiral classifier above, but this time:\n",
    "* use `nn.CrossEntropyLoss` as the loss, with `reduction=\"sum\"`\n",
    "* use `torch.optim.AdamW` as the optimizer, with learning rate `lr=0.001`\n",
    "* set a batch size of 128 samples\n",
    "* train for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258579aa",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cnn_model = CNNModel()\n",
    "cnn_model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True, pin_memory=True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=batch_size, shuffle=False, pin_memory=True\n",
    ")\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = run_epoch(\n",
    "        cnn_model, optimizer, train_dataloader, loss_fn, device\n",
    "    )\n",
    "    val_loss, val_acc = validate(cnn_model, val_dataloader, loss_fn, device)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    live_training_plot(\n",
    "        train_losses, val_losses, train_accs, val_accs, num_epochs, figsize=(10, 5)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530b8e9b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now that we trained our model, let's evaluate its performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561731be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataloader, device):\n",
    "    predictions = np.empty((0,))\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_b, y_b in tqdm(\n",
    "            test_dataloader, desc=\"Predicting\", total=len(test_dataloader)\n",
    "        ):\n",
    "            X_b = X_b.to(device)\n",
    "            y_b = y_b.long().to(device)\n",
    "            y_pred = model(X_b).argmax(axis=1).cpu().numpy()\n",
    "            predictions = np.concatenate((predictions, y_pred), axis=0)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "y_test_gt = np.array([y for _, y in test_ds])\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=batch_size, shuffle=False, pin_memory=True\n",
    ")\n",
    "y_test_predicted = predict(cnn_model, test_dataloader, device)\n",
    "\n",
    "test_acc = accuracy(y_test_predicted, y_test_gt)\n",
    "print(\"Testing accuracy =\", test_acc)\n",
    "show_samples(test_ds, \"Testing Data\", predictions=y_test_predicted, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7c240",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2> Checkpoint 4</h2>\n",
    "\n",
    "You reached the end, congratulations! In this last part, you have been introduced to CNNs as well as trained one on the infamous MNIST dataset for digit classification. \n",
    "After 10 epochs, your model should achieve a training, validation, and test accuracy of more than 95%. We will use this checkpoint to discuss why we use training, validation, and testing datasets in practice.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
